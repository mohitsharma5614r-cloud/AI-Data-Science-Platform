# âš¡ Quick Reference Card

## ğŸš€ Installation (One Command)
```bash
pip install -r requirements.txt
```

## ğŸ¯ Usage (Three Ways)

### 1. Auto-detect Everything
```bash
python main.py your_data.csv
```

### 2. Specify Target Column
```bash
python main.py your_data.csv --target column_name
```

### 3. Full Custom
```bash
python main.py your_data.csv --target price --output my_results
```

## ğŸ² Quick Demo
```bash
python quick_demo.py
```

## ğŸ“ File Structure
```
autonomous_ds_agent/
â”œâ”€â”€ main.py                 # Run this
â”œâ”€â”€ requirements.txt        # Install this
â”œâ”€â”€ quick_demo.py          # Demo this
â””â”€â”€ README.md              # Read this
```

## ğŸ“Š What You Get
```
output/
â”œâ”€â”€ data_science_report_*.pdf    # ğŸ“„ Main report
â””â”€â”€ visualizations/              # ğŸ“Š 9 charts
    â”œâ”€â”€ 01_missing_values.png
    â”œâ”€â”€ 02_data_types.png
    â”œâ”€â”€ 03_target_distribution.png
    â”œâ”€â”€ 04_correlation_heatmap.png
    â”œâ”€â”€ 05_feature_distributions.png
    â”œâ”€â”€ 06_model_comparison.png
    â”œâ”€â”€ 07_feature_importance.png
    â”œâ”€â”€ 08_confusion_matrix.png
    â””â”€â”€ 09_predictions.png
```

## ğŸ”§ Pipeline Steps
1. **Load** â†’ Auto-detect encoding
2. **Clean** â†’ Remove duplicates, handle missing, cap outliers
3. **Engineer** â†’ Create features, encode, scale, select
4. **Train** â†’ Test 7+ models, pick best
5. **Visualize** â†’ Generate 9 charts
6. **Report** â†’ Create PDF with everything

## ğŸ“ˆ Models Tested

**Classification:**
- Random Forest
- Gradient Boosting
- Logistic Regression
- Decision Tree
- K-Nearest Neighbors
- Naive Bayes
- AdaBoost

**Regression:**
- Random Forest
- Gradient Boosting
- Linear Regression
- Ridge
- Lasso
- Decision Tree
- K-Nearest Neighbors
- AdaBoost

## ğŸ“Š Metrics

**Classification:**
- Accuracy, Precision, Recall, F1-Score
- Confusion Matrix

**Regression:**
- RÂ² Score, MSE, RMSE, MAE

## âš™ï¸ Key Features

âœ… 100% Automatic
âœ… Handles missing values
âœ… Removes outliers
âœ… Creates features
âœ… Selects best model
âœ… Generates visualizations
âœ… Creates PDF report

## ğŸ“ Documentation

- **README.md** - Overview & features
- **INSTALLATION.md** - Setup guide
- **USAGE_GUIDE.md** - Detailed usage
- **WORKFLOW.md** - Pipeline details
- **PROJECT_SUMMARY.md** - Complete info

## ğŸ’¡ Common Commands

```bash
# Install
pip install -r requirements.txt

# Create sample data
python create_sample_data.py

# Run demo
python quick_demo.py

# Run on your data
python main.py data.csv --target target_col

# Check Python version
python --version

# Verify installation
python -c "import pandas, sklearn; print('OK')"
```

## ğŸ› Troubleshooting

**Issue:** Module not found
```bash
pip install -r requirements.txt
```

**Issue:** Permission denied
```bash
pip install --user -r requirements.txt
```

**Issue:** Slow installation
```bash
pip install --upgrade pip
```

## ğŸ“ Quick Help

1. Read **README.md** first
2. Run **quick_demo.py** to see it work
3. Check **USAGE_GUIDE.md** for details
4. Review **INSTALLATION.md** if issues

## â±ï¸ Expected Time

- **Small dataset (<1K):** 20-30 seconds
- **Medium (1K-10K):** 1-2 minutes
- **Large (10K-100K):** 2-5 minutes

## ğŸ¯ Best For

âœ“ Quick data analysis
âœ“ Baseline models
âœ“ Data quality check
âœ“ Automated reporting
âœ“ Learning ML
âœ“ Prototyping

## ğŸ”’ Data Requirements

- **Format:** CSV with headers
- **Size:** 100 - 100K rows (optimal)
- **Target:** Clearly identifiable column
- **Quality:** Better data = better results

## ğŸ“Š Success Indicators

âœ… PDF report generated
âœ… 9 visualizations created
âœ… Best model identified
âœ… Metrics calculated
âœ… No errors in console

## ğŸŒŸ Pro Tips

1. **Specify target explicitly** for best results
2. **Check PDF report first** - has everything
3. **Review feature importance** - understand drivers
4. **Use sample data** to learn the system
5. **Customize** by editing Python files

## ğŸ”„ Typical Workflow

```
1. Prepare CSV file
2. Install dependencies
3. Run: python main.py data.csv --target target
4. Wait for completion
5. Open PDF report
6. Review insights
7. Take action!
```

## ğŸ“¦ Dependencies (8 packages)

```
pandas          # Data manipulation
numpy           # Numerical computing
scipy           # Scientific computing
scikit-learn    # Machine learning
matplotlib      # Plotting
seaborn         # Visualization
reportlab       # PDF generation
openpyxl        # Excel support
```

## ğŸ¨ Customization Points

- **Models:** `automl_engine.py`
- **Features:** `feature_engineer.py`
- **Plots:** `visualizer.py`
- **Report:** `report_generator.py`
- **Cleaning:** `data_cleaner.py`

## ğŸ“± Quick Commands Cheat Sheet

```bash
# Setup
pip install -r requirements.txt

# Demo
python quick_demo.py

# Basic usage
python main.py data.csv

# With target
python main.py data.csv --target price

# Custom output
python main.py data.csv --target price --output results

# Create samples
python create_sample_data.py

# Help
python main.py --help
```

## ğŸ¯ Output Checklist

After running, verify:
- [ ] PDF report exists
- [ ] 9 PNG visualizations created
- [ ] No errors in console
- [ ] Report opens correctly
- [ ] Metrics look reasonable

## ğŸš¨ Common Mistakes

âŒ Forgetting to install dependencies
âŒ Wrong target column name
âŒ CSV file not found
âŒ No headers in CSV
âŒ Target column not in data

## âœ… Best Practices

âœ“ Install in virtual environment
âœ“ Specify target explicitly
âœ“ Check data quality first
âœ“ Review cleaning report
âœ“ Understand feature importance
âœ“ Validate model performance

---

**Keep this card handy for quick reference!** ğŸš€

*Bilkul AI Data Scientist jaisa!*
